{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_1pAKgdopWT"
      },
      "source": [
        "LSTM FOR SENTIMENT DETECTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BUy0vo7owBU"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybVSEnNKo6kh"
      },
      "source": [
        "def read_train():\n",
        "    train=pd.read_csv('train.csv')\n",
        "    train['text']=train['text'].astype(str)\n",
        "    train['selected_text']=train['selected_text'].astype(str)\n",
        "    return train\n",
        "\n",
        "def read_test():\n",
        "    test=pd.read_csv('test.csv')\n",
        "    test['text']=test['text'].astype(str)\n",
        "    return test\n",
        "\n",
        "def read_submission():\n",
        "    test=pd.read_csv('sample_submission.csv')\n",
        "    return test\n",
        "    \n",
        "train_df = read_train()\n",
        "test_df = read_test()\n",
        "submission_df = read_submission()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yme0bg77pICw"
      },
      "source": [
        "def jaccard(str1, str2): \n",
        "    a = set(str(str1).lower().split()) \n",
        "    b = set(str(str2).lower().split())\n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPf6FGFjpNn5"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVMq6t7qpQxV"
      },
      "source": [
        "# Drop Nan Values\n",
        "X = train_df.dropna()\n",
        "\n",
        "# Get training data\n",
        "X = train_df.drop('sentiment', axis = 1)\n",
        "\n",
        "#  Get target label\n",
        "y = train_df['sentiment']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2hEXVSMpX02"
      },
      "source": [
        "# Dataset Preprocessing\n",
        "ps = PorterStemmer()\n",
        "\n",
        "corpus = []\n",
        "\n",
        "for i in range(0, len(messages)):\n",
        "    # replace with space words other than a-1, A-Z\n",
        "    \n",
        "    review = re.sub('[^a-zA-Z]', ' ', str(messages['text'][i]))\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    \n",
        "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
        "    review = ' '.join(review)\n",
        "    corpus.append(review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK0ZmvNSpdq1"
      },
      "source": [
        "# vocabulray size\n",
        "voc_size = 5000\n",
        "# One Hot Encoding\n",
        "onehot_repr = [one_hot(words, voc_size) for words in corpus]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e0ge7d2phGd"
      },
      "source": [
        "# making all sentences of same length\n",
        "sent_length = 30\n",
        "embedded_docs = pad_sequences(onehot_repr, padding = 'pre', maxlen = sent_length)\n",
        "# Finding the numberof labels\n",
        "num_labels = len(set(train_df['sentiment']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_oWN8b0pn4k"
      },
      "source": [
        "# initializing the number of features\n",
        "embedding_vector_features = 40\n",
        "\n",
        "## Creating model\n",
        "model=Sequential()\n",
        "model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(num_labels,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytY0m2lGpr3x"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "# encode label to int\n",
        "le = preprocessing.LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "X_final = np.array(embedded_docs)\n",
        "y_final = np.array(y)\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "y_final = to_categorical(y_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGL9BnGmpubl"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qx8lRTfYpySh"
      },
      "source": [
        "%%time \n",
        "his = model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 10, batch_size = 64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLrS27cpp5Wd"
      },
      "source": [
        "def return_x_y(X):\n",
        "    \n",
        "    # Drop Nan Values\n",
        "    X = X.fillna(0)\n",
        "    \n",
        "    messages = X.copy()\n",
        "\n",
        "    messages.reset_index(inplace = True)\n",
        "\n",
        "    # Dataset Preprocessing\n",
        "    ps = PorterStemmer()\n",
        "\n",
        "    corpus = []\n",
        "\n",
        "    for i in range(0, len(messages)):\n",
        "        # replace with space words other than a-1, A-Z\n",
        "\n",
        "        review = re.sub('[^a-zA-Z]', ' ', str(messages['text'][i]))\n",
        "        review = review.lower()\n",
        "        review = review.split()\n",
        "\n",
        "        review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
        "        review = ' '.join(review)\n",
        "        corpus.append(review)\n",
        "\n",
        "    # vocabulray size\n",
        "    voc_size = 5000\n",
        "\n",
        "    onehot_repr = [one_hot(words, voc_size) for words in corpus]\n",
        "\n",
        "    # Embedding Representation\n",
        "    # making all sentences of same length\n",
        "    sent_length = 30\n",
        "    embedded_docs = pad_sequences(onehot_repr, padding = 'pre', maxlen = sent_length)\n",
        "\n",
        "    X_final = np.array(embedded_docs)\n",
        "    \n",
        "    \n",
        "    return X_final, X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUEaP4ysp7tk"
      },
      "source": [
        "# test data and pre-processing\n",
        "X_test,X_test_drop = return_x_y(test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtUg5tIHp-PN"
      },
      "source": [
        "# making prediction\n",
        "y_pred_test = model.predict_classes(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwtD1OglqCHk"
      },
      "source": [
        "len(X_test_drop['textID']), len(y_pred_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7q2-5fQqFSX"
      },
      "source": [
        "df_sub = pd.DataFrame()\n",
        "df_sub['textID'] = X_test_drop['textID']\n",
        "df_sub['selected_text'] = X_test_drop['text']\n",
        "df_sub['sentiment_predicted'] = le.inverse_transform(y_pred_test)\n",
        "df_sub['sentiment_actual'] = X_test_drop['sentiment']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL1W3uFyqHwy"
      },
      "source": [
        "df_sub.head(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2Y91EWMqK2d"
      },
      "source": [
        "df_sub.drop(['sentiment_predicted','sentiment_actual'],inplace=True,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94743PvyqNwq"
      },
      "source": [
        "# Visualizing the data\n",
        "df_sub.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}